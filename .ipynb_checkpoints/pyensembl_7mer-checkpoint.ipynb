{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39989827",
   "metadata": {},
   "source": [
    "# Extract protein-coding genes using Ensembl API (Release 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed23159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyensembl\n",
    "import pysam\n",
    "\n",
    "ref = pysam.FastaFile(\"/gpfs/ycga/project/ysm/lek/shared/resources/hg38/Homo_sapiens_assembly38.fasta\")\n",
    "ensembl = pyensembl.EnsemblRelease(release=85, species=\"human\")    #Releae 85 for my current analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6e9cef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genes in the human genome: 58051\n"
     ]
    }
   ],
   "source": [
    "all_genes = ensembl.genes()\n",
    "gene_count = len(all_genes)\n",
    "print(f\"Number of genes in the human genome: {gene_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c464d819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to obtain canonical transcript (defined as longest CDS) for each gene ID\n",
    "\n",
    "def get_canonical_transcript(gene_id):\n",
    "    transcripts = ensembl.transcript_ids_of_gene_id(gene_id)\n",
    "    max_cds_length = 0\n",
    "    canonical_transcript = None\n",
    "    for transcript_id in transcripts:\n",
    "        transcript = ensembl.transcript_by_id(transcript_id)\n",
    "        if transcript.biotype == 'protein_coding':\n",
    "            cds_start = transcript.start\n",
    "            cds_end = transcript.end\n",
    "            cds_length = cds_end - cds_start + 1\n",
    "            if cds_length > max_cds_length:\n",
    "                max_cds_length = cds_length\n",
    "                canonical_transcript = transcript\n",
    "    return canonical_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d14d1971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_complement(sequence):\n",
    "    complement = {\"A\": \"T\", \"T\": \"A\", \"C\": \"G\", \"G\": \"C\", \"N\": \"N\"}\n",
    "    return \"\".join([complement[base] for base in sequence[::]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c6c0b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trinucleotide_sequence(chromosome, position):\n",
    "    chr_chromosome = 'chr'+str(chromosome)\n",
    "    tri = ref.fetch(chr_chromosome, position-4, position+3)\n",
    "    return tri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "475625c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genes with protein coding transcripts in the human genome: 19755\n"
     ]
    }
   ],
   "source": [
    "# Store in a dictionary; keys = gene name, values = Transcript object\n",
    "\n",
    "canonical_transcripts = {}\n",
    "for gene in ensembl.genes():\n",
    "    gene_name = gene.gene_name\n",
    "    canonical_transcript = get_canonical_transcript(gene.gene_id)\n",
    "    if canonical_transcript is not None:\n",
    "        canonical_transcripts[gene_name]=canonical_transcript\n",
    "        \n",
    "print(f\"Number of genes with protein coding transcripts in the human genome: {len(canonical_transcripts)}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f386239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to Ensembl85_coding_genes.tsv\n"
     ]
    }
   ],
   "source": [
    "# Get all coding genes\n",
    "coding_genes = []\n",
    "for gene in ensembl.genes():\n",
    "    if gene.biotype == \"protein_coding\":\n",
    "        coding_genes.append((gene.name, gene.contig, gene.start, gene.end))\n",
    "\n",
    "# Define the TSV file name\n",
    "output_file = \"Ensembl85_coding_genes.tsv\"\n",
    "\n",
    "# Write coding genes' information to the TSV file\n",
    "with open(output_file, \"w\") as f:\n",
    "    f.write(\"Gene Name\\tChromosome\\tStart\\tEnd\\n\")\n",
    "    for gene_name, contig, start, end in coding_genes:\n",
    "        f.write(f\"{gene_name}\\t{contig}\\t{start}\\t{end}\\n\")\n",
    "\n",
    "print(f\"Data written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c5c4565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyensembl.sequence_data:Loaded sequence dictionary from /home/kn396/.cache/pyensembl/GRCh38/ensembl85/Homo_sapiens.GRCh38.cdna.all.fa.gz.pickle\n",
      "INFO:pyensembl.sequence_data:Loaded sequence dictionary from /home/kn396/.cache/pyensembl/GRCh38/ensembl85/Homo_sapiens.GRCh38.ncrna.fa.gz.pickle\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "canonical_transcripts_to_pos = {}\n",
    "\n",
    "for gene_name, transcript in canonical_transcripts.items():\n",
    "    try:\n",
    "        coding_sequence = transcript.coding_sequence\n",
    "        coding_ranges = transcript.coding_sequence_position_ranges\n",
    "        coding_ranges.sort()\n",
    "        contig = transcript.contig\n",
    "        absolute_positions = []\n",
    "        for ranges in coding_ranges:\n",
    "            for position in range(ranges[0]-10, ranges[1]+11):    #account for splice sites 10 bases away from breakpoint\n",
    "                base = ref.fetch('chr'+str(contig), position-1, position)\n",
    "                trinucleotide = get_trinucleotide_sequence(contig, position)\n",
    "                locus = 'chr' + contig + ':' + str(position)\n",
    "                if gene_name in canonical_transcripts_to_pos.keys():\n",
    "                    canonical_transcripts_to_pos[gene_name]['positions'][position] = {\n",
    "                    'pos':position,\n",
    "                    'locus':locus,\n",
    "                    'ref':base,\n",
    "                    'trinucleotide':trinucleotide\n",
    "                }\n",
    "                else:\n",
    "                    canonical_transcripts_to_pos[gene_name] = {\n",
    "                        'transcript':transcript,\n",
    "                        'chromosome':contig,\n",
    "                        'positions':{}\n",
    "                    }\n",
    "                    canonical_transcripts_to_pos[gene_name]['positions'][position] = {\n",
    "                        'pos':position,\n",
    "                        'locus':locus,\n",
    "                        'ref':base,\n",
    "                        'trinucleotide':trinucleotide\n",
    "                    }\n",
    "        stop_start_codon_pos = transcript.stop_codon_positions.extend(transcript.start_codon_positions)\n",
    "        if stop_start_codon_pos:\n",
    "            for position in stop_start_codon_pos:\n",
    "                if position in canonical_transcripts_to_pos[gene_name]['positions'].keys():\n",
    "                    continue\n",
    "                else:\n",
    "                    base = ref.fetch('chr'+str(contig), position-1, position)\n",
    "                    trinucleotide = get_trinucleotide_sequence(contig, position)\n",
    "                    locus = 'chr' + contig + ':' + str(position)\n",
    "                    if gene_name in canonical_transcripts_to_pos.keys():\n",
    "                        canonical_transcripts_to_pos[gene_name]['positions'][position] = {\n",
    "                        'pos':position,\n",
    "                        'locus':locus,\n",
    "                        'ref':base,\n",
    "                        'trinucleotide':trinucleotide\n",
    "                    }\n",
    "                    else:\n",
    "                        canonical_transcripts_to_pos[gene_name] = {\n",
    "                            'transcript':transcript,\n",
    "                            'chromosome':contig,\n",
    "                            'positions':{}\n",
    "                        }\n",
    "                        canonical_transcripts_to_pos[gene_name]['positions'][position] = {\n",
    "                            'pos':position,\n",
    "                            'locus':locus,\n",
    "                            'ref':base,\n",
    "                            'trinucleotide':trinucleotide\n",
    "                        }\n",
    "    except:\n",
    "        errors.append(gene_name)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caf59b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genes with complete protein coding transcripts in the human genome: 18816\n",
      "Number of genes with incomplete protein coding transcripts in the human genome: 939\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of genes with complete protein coding transcripts in the human genome: {len(canonical_transcripts_to_pos)}\") \n",
    "\n",
    "print(f\"Number of genes with incomplete protein coding transcripts in the human genome: {len(errors)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fee42c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos': 49021789,\n",
       " 'locus': 'chr12:49021789',\n",
       " 'ref': 'C',\n",
       " 'trinucleotide': 'CATCCAT'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing purposes\n",
    "canonical_transcripts_to_pos['KMT2D']['positions'][49021789]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b5c2e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene(gene_id='ENSG00000168477', gene_name='TNXB', biotype='protein_coding', contig='6', start=32041154, end=32115334, strand='-', genome='GRCh38')\n"
     ]
    }
   ],
   "source": [
    "#canonical_transcripts = {}\n",
    "for gene in ensembl.genes():\n",
    "    gene_name = gene.gene_name\n",
    "    if gene_name == \"TNXB\":\n",
    "        print(gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86cf3503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transcript(transcript_id='ENST00000375244', transcript_name='TNXB-001', gene_id='ENSG00000168477', biotype='protein_coding', contig='6', start=32041154, end=32109374, strand='-', genome='GRCh38')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canonical_transcripts['TNXB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d3284fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import mutability from 7-mer study\n",
    "\n",
    "mut = []\n",
    "\n",
    "with open(\"7mer_mut.txt\", 'r') as text:    \n",
    "    lines = text.readlines()\n",
    "    for line in lines:\n",
    "        line = line.rstrip()\n",
    "        mut.append(line.split(\"\\t\"))\n",
    "\n",
    "mut_dict = {}\n",
    "\n",
    "for i in mut[1:]:\n",
    "    ref = i[0]\n",
    "    alt = i[1]\n",
    "    change = ref+'-'+alt\n",
    "    mut_dict[change]=float(i[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d983e564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "output = [['variant', 'gene', 'from', 'to', 'mutability']]\n",
    "count = 0\n",
    "\n",
    "# Iterate through all coding bases and add information about the three possible substitutions at the base\n",
    "for gene in canonical_transcripts_to_pos.keys():\n",
    "    for position in canonical_transcripts_to_pos[gene]['positions'].keys():\n",
    "        reference = canonical_transcripts_to_pos[gene]['positions'][position]['ref']\n",
    "        locus = canonical_transcripts_to_pos[gene]['positions'][position]['locus']\n",
    "        trinucleotide_from = canonical_transcripts_to_pos[gene]['positions'][position]['trinucleotide']\n",
    "        if reference != trinucleotide_from[3]:\n",
    "            count += 1 \n",
    "            continue\n",
    "        elif reference == 'A':\n",
    "            alt1 = 'T'\n",
    "            alt2 = 'C'\n",
    "            alt3 = 'G'\n",
    "        elif reference == 'T':\n",
    "            alt1 = 'A'\n",
    "            alt2 = 'C'\n",
    "            alt3 = 'G'\n",
    "        elif reference == 'C':\n",
    "            alt1 = 'T'\n",
    "            alt2 = 'A'\n",
    "            alt3 = 'G'\n",
    "        elif reference == 'G':\n",
    "            alt1 = 'T'\n",
    "            alt2 = 'C'\n",
    "            alt3 = 'A'\n",
    "        \n",
    "        loc1 = locus + ':' + reference + ':' + alt1\n",
    "        loc2 = locus + ':' + reference + ':' + alt2\n",
    "        loc3 = locus + ':' + reference + ':' + alt3\n",
    "        \n",
    "        to1 = trinucleotide_from[:3] + alt1 + trinucleotide_from[-3:]\n",
    "        to2 = trinucleotide_from[:3] + alt2 + trinucleotide_from[-3:]\n",
    "        to3 = trinucleotide_from[:3] + alt3 + trinucleotide_from[-3:]\n",
    "        \n",
    "        mut1 = mut_dict[trinucleotide_from + '-' + to1]\n",
    "        mut2 = mut_dict[trinucleotide_from + '-' + to2]\n",
    "        mut3 = mut_dict[trinucleotide_from + '-' + to3]\n",
    "        \n",
    "        output.append([loc1, gene, trinucleotide_from, to1, mut1])\n",
    "        output.append([loc2, gene, trinucleotide_from, to2, mut2])\n",
    "        output.append([loc3, gene, trinucleotide_from, to3, mut3])\n",
    "\n",
    "# Write the output to a TSV file\n",
    "with open(\"Ensembl85_AllCodingSubstitutions_7mer_v2.tsv\", 'w', newline='') as file:\n",
    "    file_tsv = csv.writer(file, delimiter=\"\\t\")\n",
    "    file_tsv.writerows(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50b58e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106569325"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count*3 + len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51e9b821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106569325"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb75288",
   "metadata": {},
   "source": [
    "# Import into Hail for VEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "791673dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"a46a3a0c-230f-438e-ade0-e0f472d0e311\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    function drop(id) {\n",
       "      const view = Bokeh.index.get_by_id(id)\n",
       "      if (view != null) {\n",
       "        view.model.document.clear()\n",
       "        Bokeh.index.delete(view)\n",
       "      }\n",
       "    }\n",
       "\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null) {\n",
       "      drop(id)\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim()\n",
       "            drop(id)\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"a46a3a0c-230f-438e-ade0-e0f472d0e311\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.3.2.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "          for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"a46a3a0c-230f-438e-ade0-e0f472d0e311\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"a46a3a0c-230f-438e-ade0-e0f472d0e311\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.3.2.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"a46a3a0c-230f-438e-ade0-e0f472d0e311\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: No SLF4J providers were found.\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.\n",
      "SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.\n",
      "SLF4J: Ignoring binding found at [jar:file:/gpfs/gibbs/project/brueckner/kn396/conda_envs/hail_test9/lib/python3.12/site-packages/pyspark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "Running on Apache Spark version 3.3.3\n",
      "SparkUI available at http://r813u09n10.mccleary.ycrc.yale.edu:4040\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.126-ee77707f4fab\n",
      "LOGGING: writing to ./log_v2.log\n"
     ]
    }
   ],
   "source": [
    "from hl_functions import *\n",
    "hl.init(log='./log_v2.log', spark_conf={'spark.driver.memory': '10g','spark.executor.memory': '10g'},master='local[30]')\n",
    "#hl.init(master='spark://c22n03.ruddle.hpc.yale.internal:7077')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf27fe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "from pcgc_hail.hail_scripts.utils import *\n",
    "#from new_names import *\n",
    "import gnomad\n",
    "from gnomad_methods import *\n",
    "from gnomad_methods.gnomad.sample_qc import *\n",
    "\n",
    "def hl_to_txt(hl_df, name, delim='\\t'):\n",
    "    \"\"\"Convert matrix table to pandas dataframe and output to file\"\"\"\n",
    "    df = hl_df.to_pandas()\n",
    "    df.to_csv(name, sep=delim)\n",
    "\n",
    "import bokeh.io\n",
    "from bokeh.io import * \n",
    "from bokeh.layouts import *\n",
    "from bokeh.models import *\n",
    "#from matplotlib import pyplot as plt\n",
    "#hl.plot.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5d2b993",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# paths to annotation resources for hg38\n",
    "\n",
    "vep_json = '/gpfs/gibbs/pi/brueckner/14_v0/vep85-loftee-ruddle-b38.json'\n",
    "ref_data = '/gpfs/gibbs/pi/brueckner/hail_resources/combined_reference_data_grch38.ht'\n",
    "\n",
    "cadd_ht = '/gpfs/gibbs/pi/brueckner/datasets/CADD/CADD.v1.4.GRCh38.ht'\n",
    "dbnsfp_ht = '/gpfs/gibbs/pi/brueckner/datasets/dbNSFP/dbnsfp4.0a.GRCh38.ht' # 4.0 \n",
    "kg_genomes = '/gpfs/gibbs/pi/brueckner/datasets/thousand_genomes/1000_Genomes_autosomes.phase_3.GRCh38.mt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27fc7183",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-09 21:57:41.950 Hail: INFO: Reading table without type imputation\n",
      "  Loading field 'variant' as type str (not specified)\n",
      "  Loading field 'gene' as type str (not specified)\n",
      "  Loading field 'from' as type str (not specified)\n",
      "  Loading field 'to' as type str (not specified)\n",
      "  Loading field 'mutability' as type str (not specified)\n"
     ]
    }
   ],
   "source": [
    "ensembl = hl.import_table('./Ensembl85_AllCodingSubstitutions_7mer_v2.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d0c9e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl = ensembl.annotate(locus = hl.parse_variant(ensembl.variant, reference_genome = \"GRCh38\").locus)\n",
    "ensembl = ensembl.annotate(alleles = hl.parse_variant(ensembl.variant, reference_genome = \"GRCh38\").alleles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21e08444",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl = ensembl.key_by(\"locus\", 'alleles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be2e08aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from here\n",
    "ensembl_vep = hl.read_table('/gpfs/gibbs/pi/brueckner/Ensembl/Ensembl85_AllCodingSubstitutions_VEP_annotated.ht/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8acd1873",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl_vep = ensembl_vep.annotate(mut_7mer = ensembl[ensembl_vep.key].mutability)\n",
    "ensembl_vep = ensembl_vep.annotate(mut_7mer_float = hl.float(ensembl_vep.mut_7mer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9eae779",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Mutability aggregation ######\n",
    "# Define the consequence classes you want to sum up\n",
    "consequence_classes = ['synonymous_variant', 'missense_variant', 'start_lost', 'stop_gained', 'stop_lost', 'splice_donor_variant',\n",
    "                      'splice_acceptor_variant', 'splice_region_variant']\n",
    "\n",
    "results_dict = ensembl_vep.aggregate(\n",
    "    hl.agg.group_by(ensembl_vep.gene,\n",
    "        hl.agg.group_by(ensembl_vep.major_consequence,\n",
    "            hl.agg.sum(ensembl_vep.mutability_float))))\n",
    "    \n",
    "# Write the results to a TSV file\n",
    "import csv\n",
    "\n",
    "out = [['Gene'] + consequence_classes + ['frameshift_variant']]\n",
    "\n",
    "for gene in results_dict.keys():\n",
    "    gene_mut_lis = [gene]\n",
    "    for consequence in consequence_classes:\n",
    "        mutability = 0\n",
    "        if consequence in results_dict[gene].keys():\n",
    "            mutability = results_dict[gene][consequence]\n",
    "        gene_mut_lis.append(mutability)\n",
    "    frameshift_mut = 0\n",
    "    if 'stop_gained' in results_dict[gene].keys():\n",
    "        frameshift_mut = (results_dict[gene]['stop_gained'])*1.1\n",
    "    gene_mut_lis.append(frameshift_mut)\n",
    "    out.append(gene_mut_lis)\n",
    "    \n",
    "with open(\"Ensembl85_GRCh38_mutability.tsv\", 'w', newline='') as file:\n",
    "    file_tsv = csv.writer(file, delimiter = \"\\t\")\n",
    "    file_tsv.writerows(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "044b80a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "primate_ai = hl.read_table(\"/gpfs/gibbs/pi/brueckner/pcgc14_ken/output/PrimateAI-3D_scores_GRCh38.ht/\")\n",
    "\n",
    "ensembl_vep = ensembl_vep.annotate(primateai_3d = hl.if_else(hl.is_defined(primate_ai[ensembl_vep.key]), (hl.if_else(hl.is_defined(primate_ai[ensembl_vep.key].f1), primate_ai[ensembl_vep.key].f1, '0.0')), '0.0'))\n",
    "ensembl_vep = ensembl_vep.annotate(primateai_3d_float = hl.float(ensembl_vep.primateai_3d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343f4181-7c7c-4e3a-b6c7-9c69c4182b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the consequence classes you want to sum up\n",
    "consequence_classes = ['synonymous_variant', 'missense_variant', 'start_lost', 'stop_gained', 'stop_lost', 'splice_donor_variant',\n",
    "                      'splice_acceptor_variant', 'splice_region_variant']\n",
    "predictor_classes= ['mis_metaSVM', 'mis_CADD20', 'mis_CADD30', 'mis_gMVP_075', 'mis_REVEL_075', 'mis_REVEL_050',\n",
    "                   'mis_metaSVM_CADD20', 'mis_metaSVM_CADD30', 'mis_metaSVM_gmvp_075', 'mis_metaSVM_REVEL_050',\n",
    "                   'mis_metaSVM_REVEL_075', 'mis_GOF_logofunc', 'mis_CADD30_REVEL_050', 'mis_CADD30_REVEL_075',\n",
    "                   'mis_gMVP_075_REVEL_050', 'mis_gMVP_075_REVEL_075', 'mis_CADD30_gMVP_075_REVEL_050',\n",
    "                   'mis_CADD30_gMVP_075_REVEL_075', 'mis_metaSVM_CADD30_gMVP_075', 'mis_metaSVM_CADD30_gMVP_075',\n",
    "                   'mis_metaSVM_CADD30_REVEL_075', 'mis_metaSVM_CADD30_gMVP_075_REVEL_075', \n",
    "                   'mis_metaSVM_CADD30_gMVP_075_REVEL_050', 'mis_GOF_logofunc_metaSVM', 'mis_GOF_logofunc_REVEL075',\n",
    "                   'mis_GOF_logofunc_REVEL_050', 'mis_GOF_logofunc_gMVP_075',\n",
    "                   'syn_splicereg_intron_spliceAI_020', 'syn_splicereg_intron_spliceAI_050', 'syn_splicereg_intron_spliceAI_080',\n",
    "                   'mis_PrimateAI3D_080', 'mis_PrimateAI3D_050', 'mis_REVEL_050_PrimateAI3D_080',\n",
    "                   'splicereg_intron_spliceAI_020', 'splicereg_intron_spliceAI_050', 'splicereg_intron_spliceAI_080',\n",
    "                   'splicereg_spliceAI_020', 'splicereg_spliceAI_050', 'splicereg_spliceAI_080',\n",
    "                   'mis_belowREVEL_050_and_spliceAI_020', 'mis_belowREVEL_050_and_spliceAI_050', 'mis_belowREVEL_050_and_spliceAI_080']\n",
    "\n",
    "# Create a dictionary to hold the results for each gene\n",
    "results_dict = {}\n",
    "\n",
    "results_dict = ensembl_vep.aggregate(\n",
    "    hl.agg.group_by(\n",
    "        ensembl_vep.gene,\n",
    "        hl.struct(\n",
    "            mutability_per_csq=hl.agg.group_by(\n",
    "                ensembl_vep.major_consequence,\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_metaSVM=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & (ensembl_vep.meta_svm == \"D\"),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_CADD20=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & (ensembl_vep.cadd > 20),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_CADD30=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & (ensembl_vep.cadd > 30),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_gMVP_075=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & (ensembl_vep.gmvp_float > 0.75),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_REVEL_075=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & (ensembl_vep.REVEL_float > 0.75),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_REVEL_050=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & (ensembl_vep.REVEL_float > 0.50),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_metaSVM_CADD20=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & ((ensembl_vep.meta_svm == \"D\") | (ensembl_vep.cadd > 20)),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_metaSVM_CADD30=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & ((ensembl_vep.meta_svm == \"D\") | (ensembl_vep.cadd > 30)),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_metaSVM_gmvp_075=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & ((ensembl_vep.meta_svm == \"D\") | (ensembl_vep.gmvp_float > 0.75)),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_metaSVM_REVEL_050=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & ((ensembl_vep.meta_svm == \"D\") | (ensembl_vep.REVEL_float > 0.50)),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_metaSVM_REVEL_075=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & ((ensembl_vep.meta_svm == \"D\") | (ensembl_vep.REVEL_float > 0.75)),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_GOF_logofunc=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & (ensembl_vep.logofunc_pred == 'GOF'),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_CADD30_REVEL_050=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & ((ensembl_vep.cadd > 30) | (ensembl_vep.REVEL_float > 0.50)),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_CADD30_REVEL_075=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & ((ensembl_vep.cadd > 30) | (ensembl_vep.REVEL_float > 0.75)),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_gMVP_075_REVEL_050=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & ((ensembl_vep.gmvp_float > 0.75) | (ensembl_vep.REVEL_float > 0.50)),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_gMVP_075_REVEL_075=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & ((ensembl_vep.gmvp_float > 0.75) | (ensembl_vep.REVEL_float > 0.75)),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_CADD30_gMVP_075_REVEL_050=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & ((ensembl_vep.cadd > 30) | (ensembl_vep.gmvp_float > 0.75) | (ensembl_vep.REVEL_float > 0.50)),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_CADD30_gMVP_075_REVEL_075=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & ((ensembl_vep.cadd > 30) | (ensembl_vep.gmvp_float > 0.75) | (ensembl_vep.REVEL_float > 0.75)),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_metaSVM_CADD30_gMVP_075=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & ((ensembl_vep.meta_svm == \"D\") | (ensembl_vep.cadd > 30) | (ensembl_vep.gmvp_float > 0.75)),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_metaSVM_CADD30_REVEL_075=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & ((ensembl_vep.meta_svm == \"D\") | (ensembl_vep.cadd > 30) | (ensembl_vep.REVEL_float > 0.75)),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_metaSVM_CADD30_gMVP_075_REVEL_075=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & ((ensembl_vep.meta_svm == \"D\") | (ensembl_vep.cadd > 30) | (ensembl_vep.gmvp_float > 0.75) | (ensembl_vep.REVEL_float > 0.75)),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_metaSVM_CADD30_gMVP_075_REVEL_050=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & ((ensembl_vep.meta_svm == \"D\") | (ensembl_vep.cadd > 30) | (ensembl_vep.gmvp_float > 0.75) | (ensembl_vep.REVEL_float > 0.50)),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_GOF_logofunc_metaSVM=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & ((ensembl_vep.logofunc_pred == 'GOF') | (ensembl_vep.meta_svm == \"D\")),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_GOF_logofunc_REVEL075=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & ((ensembl_vep.logofunc_pred == 'GOF') | (ensembl_vep.REVEL_float > 0.75)),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_GOF_logofunc_REVEL_050=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & ((ensembl_vep.logofunc_pred == 'GOF') | (ensembl_vep.REVEL_float > 0.50)),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_GOF_logofunc_gMVP_075=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & ((ensembl_vep.logofunc_pred == 'GOF') | (ensembl_vep.gmvp_float > 0.75)),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            syn_splicereg_intron_spliceAI_020=hl.agg.filter(\n",
    "                (ensembl_vep.spliceAI_delta > 0.2) & ((ensembl_vep.major_consequence == 'intron_variant') | (ensembl_vep.major_consequence == 'splice_region_variant') | (ensembl_vep.major_consequence == 'synonymous_variant')),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            syn_splicereg_intron_spliceAI_050=hl.agg.filter(\n",
    "                (ensembl_vep.spliceAI_delta > 0.5) & ((ensembl_vep.major_consequence == 'intron_variant') | (ensembl_vep.major_consequence == 'splice_region_variant') | (ensembl_vep.major_consequence == 'synonymous_variant')),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            syn_splicereg_intron_spliceAI_080=hl.agg.filter(\n",
    "                (ensembl_vep.spliceAI_delta > 0.8) & ((ensembl_vep.major_consequence == 'intron_variant') | (ensembl_vep.major_consequence == 'splice_region_variant') | (ensembl_vep.major_consequence == 'synonymous_variant')),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_PrimateAI3D_080=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & (ensembl_vep.primateai_3d_float > 0.80),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_PrimateAI3D_050=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & (ensembl_vep.primateai_3d_float > 0.50),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_REVEL_050_PrimateAI3D_080=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & ((ensembl_vep.REVEL_float > 0.50) | (ensembl_vep.primateai_3d_float > 0.80)),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            splicereg_intron_spliceAI_020=hl.agg.filter(\n",
    "                (ensembl_vep.spliceAI_delta > 0.2) & ((ensembl_vep.major_consequence == 'intron_variant') | (ensembl_vep.major_consequence == 'splice_region_variant')),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            splicereg_intron_spliceAI_050=hl.agg.filter(\n",
    "                (ensembl_vep.spliceAI_delta > 0.5) & ((ensembl_vep.major_consequence == 'intron_variant') | (ensembl_vep.major_consequence == 'splice_region_variant')),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            splicereg_intron_spliceAI_080=hl.agg.filter(\n",
    "                (ensembl_vep.spliceAI_delta > 0.8) & ((ensembl_vep.major_consequence == 'intron_variant') | (ensembl_vep.major_consequence == 'splice_region_variant')),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            splicereg_spliceAI_020=hl.agg.filter(\n",
    "                (ensembl_vep.spliceAI_delta > 0.2) & (ensembl_vep.major_consequence == 'splice_region_variant'),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            splicereg_spliceAI_050=hl.agg.filter(\n",
    "                (ensembl_vep.spliceAI_delta > 0.5) & (ensembl_vep.major_consequence == 'splice_region_variant'),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            splicereg_spliceAI_080=hl.agg.filter(\n",
    "                (ensembl_vep.spliceAI_delta > 0.8) & (ensembl_vep.major_consequence == 'splice_region_variant'),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_belowREVEL_050_and_spliceAI_020=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & ((ensembl_vep.spliceAI_delta > 0.2) & (ensembl_vep.REVEL_float <= 0.50)),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_belowREVEL_050_and_spliceAI_050=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & ((ensembl_vep.spliceAI_delta > 0.5) & (ensembl_vep.REVEL_float <= 0.50)),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            ),\n",
    "            mis_belowREVEL_050_and_spliceAI_080=hl.agg.filter(\n",
    "                (ensembl_vep.major_consequence == 'missense_variant') & ((ensembl_vep.spliceAI_delta > 0.8) & (ensembl_vep.REVEL_float <= 0.50)),\n",
    "                hl.agg.sum(ensembl_vep.mut_7mer_float)\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Write the results to a TSV file\n",
    "import csv\n",
    "\n",
    "out = [['Gene'] + consequence_classes + ['frameshift_variant'] + predictor_classes]\n",
    "\n",
    "for gene in results_dict.keys():\n",
    "    gene_mut_lis = [gene]\n",
    "    for consequence in consequence_classes:\n",
    "        mutability = 0\n",
    "        if consequence in results_dict[gene]['mutability_per_csq'].keys():\n",
    "            mutability = results_dict[gene]['mutability_per_csq'][consequence]\n",
    "        gene_mut_lis.append(mutability)\n",
    "    frameshift_mut = 0\n",
    "    if 'stop_gained' in results_dict[gene]['mutability_per_csq'].keys():\n",
    "        frameshift_mut = (results_dict[gene]['mutability_per_csq']['stop_gained'])*1.1\n",
    "    gene_mut_lis.append(frameshift_mut)\n",
    "    for consequence in predictor_classes:\n",
    "        mutability = 0\n",
    "        if consequence in results_dict[gene].keys():\n",
    "            mutability = results_dict[gene][consequence]\n",
    "        gene_mut_lis.append(mutability)\n",
    "    out.append(gene_mut_lis)\n",
    "    \n",
    "with open(\"Ensembl85_GRCh38_mutability_predictors_7mer.tsv\", 'w', newline='') as file:\n",
    "    file_tsv = csv.writer(file, delimiter = \"\\t\")\n",
    "    file_tsv.writerows(out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
